{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x255b23e9690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedir = \"C:\\\\Users\\\\Usuário\\\\Downloads\\\\subjects\\\\SUBJECT_000001\"\n",
    "basename = \"dti\"\n",
    "L = nib.load(os.path.join(basedir, '{}_L1.nii.gz'.format(basename)))\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import getParcellation as gm\n",
    "import libcc\n",
    "import save\n",
    "\n",
    "\n",
    "def loadNiftiDTI(basedir, basename='dti', reorient=False):\n",
    "\n",
    "    # ====== MAIN FUNCTION START ===========================\n",
    "    # PRE-LOAD THE FIRST EIGENVALUE VOLUME TO GET HEADER PARAMS\n",
    "    print(os.listdir(os.path.join(basedir, '{}_L1.nii.gz'.format(basename))))\n",
    "    L = nib.load(os.path.join(basedir, '{}_L1.nii.gz'.format(basename)))\n",
    "\n",
    "    # LOAD AND BUILD EIGENVALUES VOLUME\n",
    "    evl = [L.get_data()]\n",
    "    evl.append(nib.load(os.path.join(\n",
    "        basedir, '{}_L2.nii.gz'.format(basename))).get_data())\n",
    "    evl.append(nib.load(os.path.join(\n",
    "        basedir, '{}_L3.nii.gz'.format(basename))).get_data())\n",
    "    evl = np.array(evl)\n",
    "    evl[evl < 0] = 0\n",
    "\n",
    "    # LOAD AND BUILD EIGENVECTORS VOLUME\n",
    "    evt = [nib.load(os.path.join(\n",
    "        basedir, '{}_V1.nii.gz'.format(basename))).get_data()]\n",
    "    evt.append(nib.load(os.path.join(\n",
    "        basedir, '{}_V2.nii.gz'.format(basename))).get_data())\n",
    "    evt.append(nib.load(os.path.join(\n",
    "        basedir, '{}_V3.nii.gz'.format(basename))).get_data())\n",
    "    evt = np.array(evt).transpose(0, 4, 1, 2, 3)\n",
    "\n",
    "    T = np.diag(np.ones(4))\n",
    "    if reorient:\n",
    "        # GET QFORM AFFINE MATRIX (see Nifti and nibabel specifications)\n",
    "        T = L.get_header().get_qform()\n",
    "\n",
    "        # COMPUTE ROTATION MATRIX TO ALIGN SAGITTAL PLANE\n",
    "        R = align_sagittal_plane(T)\n",
    "        evl, evt, T = rotateDTI(evl, evt, R)\n",
    "\n",
    "    return (evl, evt, T)\n",
    "\n",
    "\n",
    "def align_sagittal_plane(T):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # CANONICAL BASE (i,j,k) (HOMOGENEOUS COORDINATES)\n",
    "    c = np.array(\n",
    "        [[0, 1, 0, 0],\n",
    "         [0, 0, 1, 0],\n",
    "         [0, 0, 0, 1],\n",
    "         [1, 1, 1, 1]])\n",
    "\n",
    "    # FIND BASE V\n",
    "    V_ = np.dot(T, c)\n",
    "    V_ = V_[:3, 1:] - V_[:3, 0].reshape(3, 1)\n",
    "\n",
    "    V = np.zeros((3, 3))\n",
    "    V[np.arange(3), np.argmax(np.abs(V_), axis=1)] = 1\n",
    "    V_[V_ == 0] = 1\n",
    "    V = V * (V_/np.abs(V_))\n",
    "\n",
    "    # DESIRED BASE W\n",
    "    W = np.array([[1, 0, 0],\n",
    "                  [0, 0, -1],\n",
    "                  [0, -1, 0]])\n",
    "\n",
    "    R = np.dot(np.linalg.inv(W), V)\n",
    "    r = np.diag(np.ones(4))\n",
    "    r[:3, :3] = R\n",
    "    return r\n",
    "\n",
    "\n",
    "def rotateDTI(evl, evt, R):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    s, m, n = evl[0].shape\n",
    "\n",
    "    # ====== DETERMINE TARGET DOMAIN SIZE AND A TRANSLATION TO FIT THE ROTATED IMAGE =======\n",
    "    # VERTICES FROM THE CUBE DEFINING THE ORIGINAL VOLUME\n",
    "    cube = np.array([[0, 0, 0, 1],\n",
    "                     [0, 0, n, 1],\n",
    "                     [0, m, n, 1],\n",
    "                     [0, m, 0, 1],\n",
    "                     [s, m, 0, 1],\n",
    "                     [s, 0, 0, 1],\n",
    "                     [s, 0, n, 1],\n",
    "                     [s, m, n, 1]]).transpose()\n",
    "\n",
    "    # COMPUTE THE FIT TRANSLATION AND COMBINE WITH THE ROTATION\n",
    "    cube = np.dot(R, cube)\n",
    "    t = -cube.min(axis=1)\n",
    "    Tr = np.diag(np.ones(4, dtype='float'))\n",
    "    Tr[:3, 3] = t[:3]\n",
    "    T = np.dot(Tr, R)\n",
    "\n",
    "    # DEFINE THE TARGET DOMAIN\n",
    "    cube = cube + t.reshape(4, 1)\n",
    "    domain = np.ceil(cube.max(axis=1))[:3].astype('int')\n",
    "\n",
    "    # === TRANSFORMATION ===\n",
    "    invT = np.linalg.inv(T)\n",
    "    N = domain.prod()\n",
    "\n",
    "    # GET INDICES IN TARGET SPACE\n",
    "    points = np.array(np.indices(domain)).reshape(3, N)\n",
    "    points = np.vstack((points, np.ones(N)))\n",
    "\n",
    "    # COMPUTE POINT COORDINATES WITH NEAREST NEIGHBOR INTERPOLATION\n",
    "    points = np.dot(invT, points)[:3]\n",
    "    points = np.round(points).astype('int')\n",
    "    out_of_space = np.logical_or(points < 0, points >= np.array(\n",
    "        [s, m, n]).reshape(3, 1)).max(axis=0)\n",
    "    points[:, out_of_space] = 0\n",
    "    z, y, x = points\n",
    "\n",
    "    # APPLY TRANSFORMATION TO THE EIGENVALUES VOLUME\n",
    "    eigenvals = evl[:, z, y, x].copy()\n",
    "    eigenvals[:, out_of_space] = 0\n",
    "    eigenvals.shape = (3,) + tuple(domain)\n",
    "\n",
    "    # APPLY ROTATION TO THE EIGENVECTORS\n",
    "    evt = evt.copy()\n",
    "    evt.shape = (3, 3, s*m*n)\n",
    "    for i in range(3):\n",
    "        evt[i] = np.dot(R[:3, :3], evt[i])\n",
    "    evt.shape = (3, 3, s, m, n)\n",
    "\n",
    "    # APPLY TRANSFORMATION TO THE EIGENVECTORS VOLUME\n",
    "    eigenvects = evt[:, :, z, y, x]\n",
    "    eigenvects[:, :, out_of_space] = 0\n",
    "    eigenvects.shape = (3, 3) + tuple(domain)\n",
    "\n",
    "    return (eigenvals, eigenvects, T)\n",
    "\n",
    "\n",
    "def getFractionalAnisotropy(eigvals):\n",
    "\n",
    "    import numpy as np\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    MD = eigvals.mean(axis=0)\n",
    "    FA = np.sqrt(3*((eigvals-MD)**2).sum(axis=0)) / \\\n",
    "        np.sqrt(2*(eigvals**2).sum(axis=0))\n",
    "\n",
    "    RD = (eigvals[1]+eigvals[2])/2\n",
    "    AD = eigvals[0]\n",
    "\n",
    "    return (FA, MD, RD, AD)\n",
    "\n",
    "\n",
    "def getFissureSlice(eigvals, FA):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    MASK = (eigvals[0] > 0)\n",
    "    MASKcount = MASK.sum(axis=2).sum(axis=1)\n",
    "    FAmean = FA.mean(axis=2).mean(axis=1)\n",
    "    FAmean[MASKcount <= 0.90*MASKcount.max()] = 1\n",
    "    return (np.argmin(FAmean), FAmean)\n",
    "\n",
    "\n",
    "def run_analysis(rootdir, basename='dti'):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    eigvals, eigvects, T3 = loadNiftiDTI(\n",
    "        basedir=rootdir, basename=basename, reorient=False)  \n",
    "    print(\"Load Files\")\n",
    "\n",
    "    FA, MD, RD, AD = getFractionalAnisotropy(eigvals)\n",
    "    FA[np.isnan(FA)] = 0\n",
    "    FA[FA > 1] = 1\n",
    "\n",
    "    fissure, FA_mean = getFissureSlice(eigvals, FA)\n",
    "\n",
    "    wFA = FA*abs(eigvects[0, 0])  # weighted FA\n",
    "\n",
    "    return (wFA, FA, MD, RD, AD, fissure, eigvals, eigvects, T3)\n",
    "\n",
    "\n",
    "def segm_roqs(wFA_ms, eigvects_ms):\n",
    "\n",
    "    import numpy as np\n",
    "    from scipy.ndimage.morphology import binary_fill_holes\n",
    "    from skimage.measure import label\n",
    "    from skimage import measure\n",
    "\n",
    "    # Seed grid search - get highest FA seed within central area\n",
    "    h, w = wFA_ms.shape\n",
    "\n",
    "    # Define region to make search\n",
    "    region = np.zeros((h, w))\n",
    "    region[int(h/3):int(2*h/3), int(w/2):int(2*w/3)] = 1\n",
    "    region = wFA_ms * region\n",
    "\n",
    "    # Get the indices of maximum element in numpy array\n",
    "    fa_seed = np.amax(region)\n",
    "    seedx, seedy = np.where(region == fa_seed)\n",
    "\n",
    "    # Defining seeds positions\n",
    "    seed = [seedx, seedy]\n",
    "\n",
    "    # Get principal eigenvector (direction of maximal diffusivity)\n",
    "    max_comp_in = np.argmax(eigvects_ms[:, seed[0], seed[1]], axis=0)\n",
    "    max_comp_in = np.argmax(np.bincount(max_comp_in.ravel()))\n",
    "\n",
    "    # Max component value\n",
    "    Cmax_seed = eigvects_ms[max_comp_in, seed[0], seed[1]]\n",
    "\n",
    "    # First selection criterion\n",
    "    # Get pixels with the same maximum component (x,y or z) of the principal eigenvector\n",
    "    princ = np.argmax(eigvects_ms, axis=0)\n",
    "    fsc = princ == max_comp_in\n",
    "\n",
    "    # Calculate magnification array (MA)\n",
    "    alpha = 0.3\n",
    "    beta = 0.3\n",
    "    gamma = 0.5\n",
    "    MA = (wFA_ms-np.amax(wFA_ms)*alpha)/(np.amax(wFA_ms)*beta)+gamma\n",
    "\n",
    "    # Apply MA to eigenvector\n",
    "    ssc = np.clip(np.amax(eigvects_ms*MA, axis=0), 0, 1)\n",
    "    ssc = ssc*fsc\n",
    "\n",
    "    # Keep only pixels with Cmax greater than Cmax_seed-0.1\n",
    "    mask_cc = ssc > Cmax_seed-0.1\n",
    "    labels = label(mask_cc)\n",
    "    mask_cc = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
    "    segm = binary_fill_holes(mask_cc)\n",
    "\n",
    "    # Post processing\n",
    "    contours = measure.find_contours(segm, 0.1)\n",
    "    contour = sorted(contours, key=lambda x: len(x))[-1]\n",
    "\n",
    "    return segm\n",
    "\n",
    "\n",
    "def getFAmidline(segm, wFA_ms, n_points=200):\n",
    "\n",
    "    import numpy as np\n",
    "    from libcc import points\n",
    "\n",
    "    # Get CC's midline\n",
    "    px, py = points(segm, n_points+1)\n",
    "\n",
    "    fa_line = []\n",
    "    for aux in range(0, n_points):\n",
    "        try:\n",
    "            x = int(round(px[aux]))\n",
    "            y = int(round(py[aux]))\n",
    "            fa = wFA_ms[y, x]\n",
    "        except:\n",
    "            x = int(np.floor(px[aux]))\n",
    "            y = int(np.floor(py[aux]))\n",
    "            fa = wFA_ms[y, x]\n",
    "        fa_line.append(fa)\n",
    "\n",
    "    return fa_line\n",
    "\n",
    "\n",
    "def getScalars(segm, wFA, wMD, wRD, wAD):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    # Total value\n",
    "    meanFA = np.mean(wFA[segm == True])\n",
    "    stdFA = np.std(wFA[segm == True])\n",
    "\n",
    "    meanMD = np.mean(wMD[segm == True])\n",
    "    stdMD = np.std(wMD[segm == True])\n",
    "\n",
    "    meanRD = np.mean(wRD[segm == True])\n",
    "    stdRD = np.std(wRD[segm == True])\n",
    "\n",
    "    meanAD = np.mean(wAD[segm == True])\n",
    "    stdAD = np.std(wAD[segm == True])\n",
    "\n",
    "    return meanFA, stdFA, meanMD, stdMD, meanRD, stdRD, meanAD, stdAD\n",
    "\n",
    "\n",
    "def get_segm(data_paths):\n",
    "\n",
    "    names = []\n",
    "    meanFAList = []\n",
    "    stdFAList = []\n",
    "    meanMDList = []\n",
    "    stdMDList = []\n",
    "    meanRDList = []\n",
    "    stdRDList = []\n",
    "    meanADList = []\n",
    "    stdADList = []\n",
    "    parcellationsList = {\"ROQS\": {}}\n",
    "    times = []\n",
    "\n",
    "    for data_path in data_paths:\n",
    "        print(f\"Executando ROQS para {data_path}\", flush=True)\n",
    "\n",
    "        try:\n",
    "\n",
    "            if not data_path.endswith('.nii.gz') and not data_path.endswith('.nii'):\n",
    "                continue\n",
    "\n",
    "            folderpath = f\"{data_path}/inCCsight\"\n",
    "            filename = f\"segm_roqs\"\n",
    "\n",
    "            start = time.time()\n",
    "            code = os.path.basename(data_path)\n",
    "            sub = f'Subject_{code}'\n",
    "\n",
    "\n",
    "            wFA_v, FA_v, MD_v, RD_v, AD_v, fissure, eigvals, eigvects, affine = run_analysis(\n",
    "                data_path)\n",
    "\n",
    "            wFA = wFA_v[fissure, :, :]\n",
    "            FA = FA_v[fissure, :, :]\n",
    "            MD = MD_v[fissure, :, :]\n",
    "            RD = RD_v[fissure, :, :]\n",
    "            AD = AD_v[fissure, :, :]\n",
    "            eigvects_ms = abs(eigvects[0, :, fissure])\n",
    "\n",
    "            scalar_maps = (FA, MD, RD, AD)\n",
    "            segmentation = segm_roqs(wFA, eigvects_ms)\n",
    "\n",
    "            values = gm.getParcellation(segmentation, FA)\n",
    "            parcellation_dict = gm.parcellations_dfs_dicts(scalar_maps, values)\n",
    "            parcellationsList[\"ROQS\"][sub] = parcellation_dict\n",
    "\n",
    "            scalar_statistics = getScalars(segmentation, FA, MD, RD, AD)\n",
    "\n",
    "            # Midline\n",
    "            scalar_midlines = {}\n",
    "\n",
    "            try:\n",
    "                scalar_midlines['FA'] = getFAmidline(\n",
    "                    segmentation, FA, n_points=200)\n",
    "                scalar_midlines['MD'] = getFAmidline(\n",
    "                    segmentation, MD, n_points=200)\n",
    "                scalar_midlines['RD'] = getFAmidline(\n",
    "                    segmentation, RD, n_points=200)\n",
    "                scalar_midlines['AD'] = getFAmidline(\n",
    "                    segmentation, AD, n_points=200)\n",
    "            except:\n",
    "                scalar_midlines = {'FA': [], 'MD': [], 'RD': [], 'AD': []}\n",
    "\n",
    "            # Check segmentation errors (True/False)\n",
    "            error_flag = False\n",
    "            error_prob = []\n",
    "            try:\n",
    "                error_flag, error_prob = libcc.checkShapeSign(\n",
    "                    segmentation, shape_imports, threshold=0.6)\n",
    "            except:\n",
    "                error_flag = True\n",
    "\n",
    "            # data_tuple = (segmentation, scalar_maps, scalar_statistics, scalar_midlines, error_prob, parcellation_dict)\n",
    "\n",
    "            names.append(sub)\n",
    "            meanFAList.append(scalar_statistics[0])\n",
    "            stdFAList.append(scalar_statistics[1])\n",
    "            meanMDList.append(scalar_statistics[2])\n",
    "            stdMDList.append(scalar_statistics[3])\n",
    "            meanRDList.append(scalar_statistics[4])\n",
    "            stdRDList.append(scalar_statistics[5])\n",
    "            meanADList.append(scalar_statistics[6])\n",
    "            stdADList.append(scalar_statistics[7])\n",
    "\n",
    "            name = sub\n",
    "            meanFA = scalar_statistics[0] \n",
    "            stdFA = scalar_statistics[1]\n",
    "            meanMD = scalar_statistics[2]\n",
    "            stdMD = scalar_statistics[3]\n",
    "            meanRD = scalar_statistics[4]\n",
    "            stdRD = scalar_statistics[5]\n",
    "            meanAD = scalar_statistics[6]\n",
    "            stdAD = scalar_statistics[7]\n",
    "            \n",
    "            sub_data = {}\n",
    "\n",
    "            names_maps = list([\"name\", \"meanFA\", \"stdFA\", \"meanMD\", \"stdMD\", \"meanRD\", \"stdRD\", \"meanAD\", \"stdAD\"])\n",
    "            scalars_values = list([name,scalar_statistics[0], scalar_statistics[1], scalar_statistics[2], scalar_statistics[3], scalar_statistics[4], scalar_statistics[5], scalar_statistics[6], scalar_statistics[7]])\n",
    "            \n",
    "\n",
    "            for i in range(0, len(names_maps)):\n",
    "                sub_data[names_maps[i]] = scalars_values[i]\n",
    "            \n",
    "            # Salvando os Dados\n",
    "            canvas = np.zeros(wFA_v.shape, dtype='int32')\n",
    "            canvas[fissure, :, :] = segmentation\n",
    "\n",
    "            save.save_nii(data_path, 'segm_roqs', canvas, affine)\n",
    "            # save.save_os(data_path, filename, data_tuple)\n",
    "\n",
    "            end = time.time()\n",
    "            time_total = round(end - start, 2)\n",
    "            times.append(time_total)\n",
    "\n",
    "            gm.adjust_dict_parcellations_statistics(parcellationsList, sub_data, data_path)\n",
    "\n",
    "        except:\n",
    "            print(f\"{data_path} Failed.\")\n",
    "            continue\n",
    "        \n",
    "    subjects = {\"Names\": names, \"FA\": meanFAList, \"FA StdDev\": stdFAList, \"MD\": meanMDList, \"MD StdDev\": stdMDList, \"RD\": meanRDList, \"RD StdDev\": stdRDList, \"AD\": meanADList, \"AD StdDev\": stdADList, \"Time\": times}\n",
    "\n",
    "    df = pd.DataFrame(subjects)\n",
    "    df.to_csv(\"./data/roqs_based.csv\", sep=\";\")\n",
    "    df.to_csv(\"../csvs/roqs_based.csv\", sep=\";\")\n",
    "    #gm.adjust_dict_parcellations_statistics(parcellationsList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUBJECT_000001']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "folder_mri = \"C:/Users/Usuário/Downloads/subjects/\"\n",
    "print(os.listdir(folder_mri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando ROQS para /$AV_ASW\n",
      "Executando ROQS para /$Recycle.Bin\n",
      "Executando ROQS para /$WinREAgent\n",
      "Executando ROQS para /Arquivos de Programas\n",
      "Executando ROQS para /avast! sandbox\n",
      "Executando ROQS para /bootTel.dat\n",
      "Executando ROQS para /Config.Msi\n",
      "Executando ROQS para /Documents and Settings\n",
      "Executando ROQS para /DumpStack.log\n",
      "Executando ROQS para /DumpStack.log.tmp\n",
      "Executando ROQS para /found.000\n",
      "Executando ROQS para /hiberfil.sys\n",
      "Executando ROQS para /MSOCache\n",
      "Executando ROQS para /OneDriveTemp\n",
      "Executando ROQS para /pagefile.sys\n",
      "Executando ROQS para /PerfLogs\n",
      "Executando ROQS para /Program Files\n",
      "Executando ROQS para /Program Files (x86)\n",
      "Executando ROQS para /ProgramData\n",
      "Executando ROQS para /Recovery\n",
      "Executando ROQS para /Riot Games\n",
      "Executando ROQS para /swapfile.sys\n",
      "Executando ROQS para /System Volume Information\n",
      "Executando ROQS para /Users\n",
      "Executando ROQS para /Windows\n",
      "Executando ROQS para /XboxGames\n",
      "Executando ROQS para /$AV_ASW\n",
      "Executando ROQS para /$Recycle.Bin\n",
      "Executando ROQS para /$WinREAgent\n",
      "Executando ROQS para /Arquivos de Programas\n",
      "Executando ROQS para /avast! sandbox\n",
      "Executando ROQS para /bootTel.dat\n",
      "Executando ROQS para /Config.Msi\n",
      "Executando ROQS para /Documents and Settings\n",
      "Executando ROQS para /DumpStack.log\n",
      "Executando ROQS para /DumpStack.log.tmp\n",
      "Executando ROQS para /found.000\n",
      "Executando ROQS para /hiberfil.sys\n",
      "Executando ROQS para /MSOCache\n",
      "Executando ROQS para /OneDriveTemp\n",
      "Executando ROQS para /pagefile.sys\n",
      "Executando ROQS para /PerfLogs\n",
      "Executando ROQS para /Program Files\n",
      "Executando ROQS para /Program Files (x86)\n",
      "Executando ROQS para /ProgramData\n",
      "Executando ROQS para /Recovery\n",
      "Executando ROQS para /Riot Games\n",
      "Executando ROQS para /swapfile.sys\n",
      "Executando ROQS para /System Volume Information\n",
      "Executando ROQS para /Users\n",
      "Executando ROQS para /Windows\n",
      "Executando ROQS para /XboxGames\n",
      "Executando ROQS para /$AV_ASW\n",
      "Executando ROQS para /$Recycle.Bin\n",
      "Executando ROQS para /$WinREAgent\n",
      "Executando ROQS para /Arquivos de Programas\n",
      "Executando ROQS para /avast! sandbox\n",
      "Executando ROQS para /bootTel.dat\n",
      "Executando ROQS para /Config.Msi\n",
      "Executando ROQS para /Documents and Settings\n",
      "Executando ROQS para /DumpStack.log\n",
      "Executando ROQS para /DumpStack.log.tmp\n",
      "Executando ROQS para /found.000\n",
      "Executando ROQS para /hiberfil.sys\n",
      "Executando ROQS para /MSOCache\n",
      "Executando ROQS para /OneDriveTemp\n",
      "Executando ROQS para /pagefile.sys\n",
      "Executando ROQS para /PerfLogs\n",
      "Executando ROQS para /Program Files\n",
      "Executando ROQS para /Program Files (x86)\n",
      "Executando ROQS para /ProgramData\n",
      "Executando ROQS para /Recovery\n",
      "Executando ROQS para /Riot Games\n",
      "Executando ROQS para /swapfile.sys\n",
      "Executando ROQS para /System Volume Information\n",
      "Executando ROQS para /Users\n",
      "Executando ROQS para /Windows\n",
      "Executando ROQS para /XboxGames\n",
      "Executando ROQS para /$AV_ASW\n",
      "Executando ROQS para /$Recycle.Bin\n",
      "Executando ROQS para /$WinREAgent\n",
      "Executando ROQS para /Arquivos de Programas\n",
      "Executando ROQS para /avast! sandbox\n",
      "Executando ROQS para /bootTel.dat\n",
      "Executando ROQS para /Config.Msi\n",
      "Executando ROQS para /Documents and Settings\n",
      "Executando ROQS para /DumpStack.log\n",
      "Executando ROQS para /DumpStack.log.tmp\n",
      "Executando ROQS para /found.000\n",
      "Executando ROQS para /hiberfil.sys\n",
      "Executando ROQS para /MSOCache\n",
      "Executando ROQS para /OneDriveTemp\n",
      "Executando ROQS para /pagefile.sys\n",
      "Executando ROQS para /PerfLogs\n",
      "Executando ROQS para /Program Files\n",
      "Executando ROQS para /Program Files (x86)\n",
      "Executando ROQS para /ProgramData\n",
      "Executando ROQS para /Recovery\n",
      "Executando ROQS para /Riot Games\n",
      "Executando ROQS para /swapfile.sys\n",
      "Executando ROQS para /System Volume Information\n",
      "Executando ROQS para /Users\n",
      "Executando ROQS para /Windows\n",
      "Executando ROQS para /XboxGames\n",
      "Executando ROQS para /$AV_ASW\n",
      "Executando ROQS para /$Recycle.Bin\n",
      "Executando ROQS para /$WinREAgent\n",
      "Executando ROQS para /Arquivos de Programas\n",
      "Executando ROQS para /avast! sandbox\n",
      "Executando ROQS para /bootTel.dat\n",
      "Executando ROQS para /Config.Msi\n",
      "Executando ROQS para /Documents and Settings\n",
      "Executando ROQS para /DumpStack.log\n",
      "Executando ROQS para /DumpStack.log.tmp\n",
      "Executando ROQS para /found.000\n",
      "Executando ROQS para /hiberfil.sys\n",
      "Executando ROQS para /MSOCache\n",
      "Executando ROQS para /OneDriveTemp\n",
      "Executando ROQS para /pagefile.sys\n",
      "Executando ROQS para /PerfLogs\n",
      "Executando ROQS para /Program Files\n",
      "Executando ROQS para /Program Files (x86)\n",
      "Executando ROQS para /ProgramData\n",
      "Executando ROQS para /Recovery\n",
      "Executando ROQS para /Riot Games\n",
      "Executando ROQS para /swapfile.sys\n",
      "Executando ROQS para /System Volume Information\n",
      "Executando ROQS para /Users\n",
      "Executando ROQS para /Windows\n",
      "Executando ROQS para /XboxGames\n"
     ]
    }
   ],
   "source": [
    "all_subjects = []\n",
    "\n",
    "for folder in folder_mri:\n",
    "    subjects = glob.glob(os.path.join(folder, \"*\"))\n",
    "\n",
    "    for subject in subjects:\n",
    "        all_subjects.append(subject)\n",
    "\n",
    "get_segm(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
